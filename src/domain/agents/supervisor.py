from langgraph.prebuilt import create_react_agent
from src.domain.agents.graph_writer import graph_agent
from src.domain.agents.topic_model import tm_agent
from src.domain.prompts.agent_prompts import SUPERVISOR_PROMPT
from src.utils.model_init import get_openai_model
from langchain.tools import Tool

model = get_openai_model()

def wrap_agent(agent, name):
    def _run(*args, **kwargs):
        print(f"[Supervisor] Invoking agent: {name}", flush=True)
        result = agent.run(*args, **kwargs)
        print(f"[{name}] Result: {result}", flush=True)
        return result
    return Tool.from_function(name=name, func=_run, description=f"{name} agent")

graph_tool = wrap_agent(graph_agent, "graph_agent")
tm_tool = wrap_agent(tm_agent, "tm_agent")

tools = [graph_tool, tm_tool]

supervisor = create_react_agent(model, tools, prompt=SUPERVISOR_PROMPT)

def run_supervisor(query: str) -> dict:
    """
    Executes the supervisor agent with the given user query.

    Args:
        query (str): The input prompt to process.

    Returns:
        dict: The structured response generated by the supervisor agent.
    """
    try:
        print("Running supervisor agent...", flush=True)
        response = supervisor.invoke({
            "input": query,
            "agent_scratchpad": [],
            "is_last_step": False,
            "messages": [],
            "remaining_steps": 10,
            "recursion_limit": 10
        })
        print("Supervisor response:", response, flush=True)
        return response
    except Exception as e:
        error_message = f"Error during supervisor execution: {e}"
        print(error_message, flush=True)
        return {"error": error_message}